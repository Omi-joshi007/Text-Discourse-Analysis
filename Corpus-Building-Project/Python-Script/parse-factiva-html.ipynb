{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Factiva HTML to corpus of TXT files\n",
    "\n",
    "This is a Jupyter Notebook to parse the HTML output from Factiva \"save\" operations and output a set of separate txt files for text analysis.\n",
    "\n",
    "## Getting files from Factiva\n",
    "Factiva allows you to export batches of files to HTML. Here are the steps.\n",
    "1. Do your search.\n",
    "2. Check the checkbox to select all the articles on the page.\n",
    "3. Click the \"save\" icon (it looks like a disk ðŸ’¾) and click \"Article format\".\n",
    "4. A new browser window should open with all the articles. Save the HTML of this file using Ctrl-S - make sure you are saving as something like \"Web Page, HTML only\" - this will differ based on your browser.\n",
    "5. Repeat the process 2-4 for each subsequent page of results.\n",
    "6. Place these files in the directory you have specified below for `directory_with_factivahtml`. Note: the code scans for files ending in .html to process - so make sure the files have this file extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't already have it - then you should install beautifulsoup e.g. pip install beautifulsoup4\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import datetime\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you should have two directories factivahtml (put your output files from Factiva here) \n",
    "# and corpus (this is where you corpus will get created)\n",
    "directory_with_factivahtml = 'inputfactivahtml/'\n",
    "directory_to_output_corpus = 'outputcorpus/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------inputfactivahtml/Factiva.html|1-----------------\n",
      "doc#: Document PJRC000020240314ek5100003\n",
      "headline: Evaluating Racial and Ethnic Invariance Among the Correlates of Guilty Pleas: A Focus on the Effect of Court Legitimacy, Attorney Type, Satisfaction, and Plea-Offer Evaluation\n",
      "author: Jaynes Chae M; Lee Jacqueline G; N Franks Heath \n",
      "words: 240 words\n",
      "date: 1 May 2024\n",
      "publisher:  Journal of Research in Crime & Delinquency\n",
      "short publisher id:  PJRC\n",
      "copyright: Â© 2024 Journal of Research in Crime & Delinquency. Provided by ProQuest Information and Learning. All Rights Reserved. \n",
      "Language: English\n",
      "Wrote file:  outputcorpus/2024-05-01-PJRC-PJRC000020240314ek5100003.txt\n"
     ]
    }
   ],
   "source": [
    "factivafiles = [f for f in glob.glob(directory_with_factivahtml + \"*.html\")]\n",
    "for factivafile in factivafiles:\n",
    "    soup = BeautifulSoup(open(factivafile, encoding='utf8'), \"html.parser\")\n",
    "    i = 0\n",
    "    for article in soup.select(\".article .article,#lastArticle\"):\n",
    "        i += 1\n",
    "        print('---------------' + factivafile + '|' + str(i) + '-----------------')\n",
    "        doc_string = article.find_all('p', attrs={'class': None}, string=re.compile('^Document ')) \n",
    "        print('doc#:', doc_string[0].get_text())\n",
    "        for headline in article.select(\"#hd\"):\n",
    "            print('headline:', headline.get_text().strip())\n",
    "            body = headline.get_text().strip() + \"\\n\"\n",
    "        for author in article.select(\"div.author\"):\n",
    "            print('author:', author.get_text())\n",
    "        words_string = article.find_all('div', attrs={'class': None}, string=re.compile('[0-9]{1,2} words')) \n",
    "        print('words:', words_string[0].get_text())\n",
    "        date_string = article.find_all('div', attrs={'class': None}, string=re.compile('[0-9]{1,2} [A-Za-z]{1,} [0-9]{4}')) \n",
    "        print('date:', date_string[0].get_text())\n",
    "        time_string = article.find_all('div', attrs={'class': None}, string=re.compile('[0-9]{2}:[0-9]{2}')) \n",
    "        if (len(time_string) > 0):\n",
    "            print('time:', time_string[0].get_text())\n",
    "            print('publisher: ', time_string[0].next_sibling.get_text()) #text publisher\n",
    "            short_publisher_id = time_string[0].next_sibling.next_sibling.get_text()\n",
    "        else:\n",
    "            print('publisher: ', date_string[0].next_sibling.get_text()) #text publisher\n",
    "            short_publisher_id = date_string[0].next_sibling.next_sibling.get_text()\n",
    "        print('short publisher id: ', short_publisher_id) #short publisher\n",
    "        copyright_string = article.find_all('div', attrs={'class': None}, string=re.compile('.*(All Rights Reserved|\\(c\\)|Copyright|Â©).*', flags=re.IGNORECASE)) \n",
    "        language = ''\n",
    "        if (len(copyright_string) > 0):\n",
    "            print('copyright:', copyright_string[0].get_text())\n",
    "            language = copyright_string[0].previous_sibling.get_text()\n",
    "            print('Language:', copyright_string[0].previous_sibling.get_text())\n",
    "        else:\n",
    "            print('Warning: No language!!!!!')\n",
    "\n",
    "        for paragraph in article.select(\".articleParagraph\"):\n",
    "            body += paragraph.get_text().strip() + \"\\n\"\n",
    "\n",
    "        format_str = '%d %B %Y'\n",
    "        datetime_obj = datetime.datetime.strptime(date_string[0].get_text(), format_str)\n",
    "        fileid = str(datetime_obj.date()) + '-' + short_publisher_id + '-' + doc_string[0].get_text().replace('Document ','')\n",
    "        if (language == 'English'):\n",
    "            with open(directory_to_output_corpus + fileid + '.txt', 'w', encoding='utf8') as f:\n",
    "                f.write(body)\n",
    "                f.close()\n",
    "                print('Wrote file: ', directory_to_output_corpus + fileid + '.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
